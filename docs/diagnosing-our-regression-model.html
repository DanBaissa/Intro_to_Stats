<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Diagnosing Our Regression Model | A Basic Introduction to Stats Concepts</title>
  <meta name="description" content="“Dive into the world of statistics with ‘Introduction to Basic Stats Concepts.’ This book is designed to demystify complex statistical topics and make them accessible to everyone. Whether you’re a student starting out, a professional looking to refresh your knowledge, or a curious mind eager to understand how data shapes our understanding of the world, this book is for you. Featuring practical examples, detailed explanations, and interactive R code snippets, this guide is your first step towards mastering the fundamentals of statistics. Join us as we explore everything from p-values to machine learning, all explained in a clear and engaging manner.”" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Diagnosing Our Regression Model | A Basic Introduction to Stats Concepts" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="“Dive into the world of statistics with ‘Introduction to Basic Stats Concepts.’ This book is designed to demystify complex statistical topics and make them accessible to everyone. Whether you’re a student starting out, a professional looking to refresh your knowledge, or a curious mind eager to understand how data shapes our understanding of the world, this book is for you. Featuring practical examples, detailed explanations, and interactive R code snippets, this guide is your first step towards mastering the fundamentals of statistics. Join us as we explore everything from p-values to machine learning, all explained in a clear and engaging manner.”" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Diagnosing Our Regression Model | A Basic Introduction to Stats Concepts" />
  
  <meta name="twitter:description" content="“Dive into the world of statistics with ‘Introduction to Basic Stats Concepts.’ This book is designed to demystify complex statistical topics and make them accessible to everyone. Whether you’re a student starting out, a professional looking to refresh your knowledge, or a curious mind eager to understand how data shapes our understanding of the world, this book is for you. Featuring practical examples, detailed explanations, and interactive R code snippets, this guide is your first step towards mastering the fundamentals of statistics. Join us as we explore everything from p-values to machine learning, all explained in a clear and engaging manner.”" />
  

<meta name="author" content="Daniel K Baissa" />


<meta name="date" content="2024-06-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-to-linear-regression.html"/>
<link rel="next" href="diving-into-spatial-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Basic Introduction to Stats Concepts</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#welcome-to-our-statistical-journey"><i class="fa fa-check"></i><b>1.1</b> Welcome to Our Statistical Journey!</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#why-this-book"><i class="fa fa-check"></i><b>1.1.1</b> Why This Book?</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#what-will-you-learn"><i class="fa fa-check"></i><b>1.1.2</b> What Will You Learn?</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i><b>1.1.3</b> How to Use This Book</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#lets-get-started"><i class="fa fa-check"></i><b>1.2</b> Let’s Get Started!</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html"><i class="fa fa-check"></i><b>2</b> Exploring Probability Distributions with Visuals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#normal-distribution-the-bell"><i class="fa fa-check"></i><b>2.1</b> Normal Distribution: The Bell</a></li>
<li class="chapter" data-level="2.2" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#binomial-distribution-counting-successes"><i class="fa fa-check"></i><b>2.2</b> Binomial Distribution: Counting Successes</a></li>
<li class="chapter" data-level="2.3" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#poisson-distribution-counting-events"><i class="fa fa-check"></i><b>2.3</b> Poisson Distribution: Counting Events</a></li>
<li class="chapter" data-level="2.4" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#negative-binomial-distribution-waiting-for-successes"><i class="fa fa-check"></i><b>2.4</b> Negative Binomial Distribution: Waiting for Successes</a></li>
<li class="chapter" data-level="2.5" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#central-limit-theorem-what-happens-when-distributions-come-together"><i class="fa fa-check"></i><b>2.5</b> Central Limit Theorem: What Happens When Distributions Come Together?</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#central-limit-theorem-in-r"><i class="fa fa-check"></i><b>2.5.1</b> Central Limit Theorem in R</a></li>
<li class="chapter" data-level="2.5.2" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#whats-happening-here"><i class="fa fa-check"></i><b>2.5.2</b> What’s Happening Here?</a></li>
<li class="chapter" data-level="2.5.3" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#implications"><i class="fa fa-check"></i><b>2.5.3</b> Implications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html"><i class="fa fa-check"></i><b>3</b> Understanding the p-value</a>
<ul>
<li class="chapter" data-level="3.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#what-is-a-p-value"><i class="fa fa-check"></i><b>3.1</b> What is a p-value?</a></li>
<li class="chapter" data-level="3.2" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#visualizing-p-values-how-sigma-frames-our-understanding"><i class="fa fa-check"></i><b>3.2</b> Visualizing p-values: How Sigma Frames Our Understanding</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#the-concept-of-sigma"><i class="fa fa-check"></i><b>3.2.1</b> The Concept of Sigma</a></li>
<li class="chapter" data-level="3.2.2" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#the-plot-of-sigma-and-p-values"><i class="fa fa-check"></i><b>3.2.2</b> The Plot of Sigma and p-values</a></li>
<li class="chapter" data-level="3.2.3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#whats-going-on-here"><i class="fa fa-check"></i><b>3.2.3</b> What’s Going on Here?</a></li>
<li class="chapter" data-level="3.2.4" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#takeaway"><i class="fa fa-check"></i><b>3.2.4</b> Takeaway</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#exploring-p-values-through-simulation"><i class="fa fa-check"></i><b>3.3</b> Exploring p-values through Simulation</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#simulating-multiple-t-tests"><i class="fa fa-check"></i><b>3.3.1</b> Simulating Multiple t-tests</a></li>
<li class="chapter" data-level="3.3.2" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#whats-happening-here-1"><i class="fa fa-check"></i><b>3.3.2</b> What’s Happening Here?</a></li>
<li class="chapter" data-level="3.3.3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#insights-from-the-simulation"><i class="fa fa-check"></i><b>3.3.3</b> Insights from the Simulation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#false-positives-and-false-negatives"><i class="fa fa-check"></i><b>3.4</b> False Positives and False Negatives</a></li>
<li class="chapter" data-level="3.5" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#understanding-power-through-elephants"><i class="fa fa-check"></i><b>3.5</b> Understanding Power Through Elephants</a></li>
<li class="chapter" data-level="3.6" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#beyond-p-values-the-importance-of-substantive-significance"><i class="fa fa-check"></i><b>3.6</b> Beyond p-values: The Importance of Substantive Significance</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#example-water-vs.-cyanide"><i class="fa fa-check"></i><b>3.6.1</b> Example: Water vs. Cyanide</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html"><i class="fa fa-check"></i><b>4</b> Dive into the t-test</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#basics-of-the-t-test"><i class="fa fa-check"></i><b>4.1</b> Basics of the t-test</a></li>
<li class="chapter" data-level="4.2" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#step-by-step-example-using-simulated-data"><i class="fa fa-check"></i><b>4.2</b> Step-by-Step Example Using Simulated Data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#setting-up-the-problem"><i class="fa fa-check"></i><b>4.2.1</b> Setting Up the Problem</a></li>
<li class="chapter" data-level="4.2.2" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#performing-an-independent-samples-t-test"><i class="fa fa-check"></i><b>4.2.2</b> Performing an Independent Samples t-test</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#interpreting-results"><i class="fa fa-check"></i><b>4.3</b> Interpreting Results</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html"><i class="fa fa-check"></i><b>5</b> A/B Testing Explained</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#what-is-ab-testing"><i class="fa fa-check"></i><b>5.1</b> What is A/B Testing?</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#running-an-ab-test"><i class="fa fa-check"></i><b>5.1.1</b> Running an A/B Test</a></li>
<li class="chapter" data-level="5.1.2" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#example-scenario"><i class="fa fa-check"></i><b>5.1.2</b> Example Scenario</a></li>
<li class="chapter" data-level="5.1.3" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#implementing-in-r"><i class="fa fa-check"></i><b>5.1.3</b> Implementing in R</a></li>
<li class="chapter" data-level="5.1.4" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#analyzing-results"><i class="fa fa-check"></i><b>5.1.4</b> Analyzing Results</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#considerations-and-best-practices"><i class="fa fa-check"></i><b>5.2</b> Considerations and Best Practices</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#the-concept"><i class="fa fa-check"></i><b>6.1</b> The Concept</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#visualizing-simple-attempts"><i class="fa fa-check"></i><b>6.1.1</b> Visualizing Simple Attempts</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#finding-the-best-fit"><i class="fa fa-check"></i><b>6.1.2</b> Finding the Best Fit</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#understanding-the-interpretation"><i class="fa fa-check"></i><b>6.2</b> Understanding the Interpretation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#going-a-step-further-linear-algebra"><i class="fa fa-check"></i><b>6.2.1</b> Going a Step Further: Linear Algebra</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>6.3</b> Assumptions of Linear Regression</a></li>
<li class="chapter" data-level="6.4" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#extending-linear-regression"><i class="fa fa-check"></i><b>6.4</b> Extending Linear Regression</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#spatial-regression"><i class="fa fa-check"></i><b>6.4.1</b> Spatial Regression</a></li>
<li class="chapter" data-level="6.4.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#robust-estimation"><i class="fa fa-check"></i><b>6.4.2</b> Robust Estimation</a></li>
<li class="chapter" data-level="6.4.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#robust-standard-errors"><i class="fa fa-check"></i><b>6.4.3</b> Robust Standard Errors</a></li>
<li class="chapter" data-level="6.4.4" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#handling-serial-autocorrelation-in-time-series-data"><i class="fa fa-check"></i><b>6.4.4</b> Handling Serial Autocorrelation in Time Series Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html"><i class="fa fa-check"></i><b>7</b> Diagnosing Our Regression Model</a>
<ul>
<li class="chapter" data-level="7.1" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#residuals-analysis"><i class="fa fa-check"></i><b>7.1</b> Residuals Analysis</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#why-focus-on-residuals"><i class="fa fa-check"></i><b>7.1.1</b> Why Focus on Residuals?</a></li>
<li class="chapter" data-level="7.1.2" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#plotting-residuals-against-fitted-values"><i class="fa fa-check"></i><b>7.1.2</b> Plotting Residuals Against Fitted Values</a></li>
<li class="chapter" data-level="7.1.3" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#what-to-look-for-in-the-plot"><i class="fa fa-check"></i><b>7.1.3</b> What to Look For in the Plot</a></li>
<li class="chapter" data-level="7.1.4" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#next-steps"><i class="fa fa-check"></i><b>7.1.4</b> Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#checking-for-normality-in-residuals"><i class="fa fa-check"></i><b>7.2</b> Checking for Normality in Residuals</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#why-normality"><i class="fa fa-check"></i><b>7.2.1</b> Why Normality?</a></li>
<li class="chapter" data-level="7.2.2" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#using-a-q-q-plot-to-check-normality"><i class="fa fa-check"></i><b>7.2.2</b> Using a Q-Q Plot to Check Normality</a></li>
<li class="chapter" data-level="7.2.3" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#interpreting-the-q-q-plot"><i class="fa fa-check"></i><b>7.2.3</b> Interpreting the Q-Q Plot</a></li>
<li class="chapter" data-level="7.2.4" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#what-if-residuals-arent-normal"><i class="fa fa-check"></i><b>7.2.4</b> What if Residuals Aren’t Normal?</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#influence-measures"><i class="fa fa-check"></i><b>7.3</b> Influence Measures</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#cooks-distance"><i class="fa fa-check"></i><b>7.3.1</b> Cook’s Distance</a></li>
<li class="chapter" data-level="7.3.2" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#using-influenceplot-for-detailed-diagnostic"><i class="fa fa-check"></i><b>7.3.2</b> Using <code>influencePlot</code> for Detailed Diagnostic</a></li>
<li class="chapter" data-level="7.3.3" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#interpreting-the-influence-plot"><i class="fa fa-check"></i><b>7.3.3</b> Interpreting the Influence Plot</a></li>
<li class="chapter" data-level="7.3.4" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#actions-to-take"><i class="fa fa-check"></i><b>7.3.4</b> Actions to Take</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#multicollinearity-check"><i class="fa fa-check"></i><b>7.4</b> Multicollinearity Check</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#why-worry-about-multicollinearity"><i class="fa fa-check"></i><b>7.4.1</b> Why Worry About Multicollinearity?</a></li>
<li class="chapter" data-level="7.4.2" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#checking-for-multicollinearity-with-vif"><i class="fa fa-check"></i><b>7.4.2</b> Checking for Multicollinearity with VIF</a></li>
<li class="chapter" data-level="7.4.3" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#interpreting-vif-values"><i class="fa fa-check"></i><b>7.4.3</b> Interpreting VIF Values</a></li>
<li class="chapter" data-level="7.4.4" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#how-to-address-high-vifs"><i class="fa fa-check"></i><b>7.4.4</b> How to Address High VIFs</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#autocorrelation-test"><i class="fa fa-check"></i><b>7.5</b> Autocorrelation Test</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#what-is-autocorrelation"><i class="fa fa-check"></i><b>7.5.1</b> What is Autocorrelation?</a></li>
<li class="chapter" data-level="7.5.2" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#testing-autocorrelation-with-durbin-watson"><i class="fa fa-check"></i><b>7.5.2</b> Testing Autocorrelation with Durbin-Watson</a></li>
<li class="chapter" data-level="7.5.3" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#interpreting-durbin-watson-statistic"><i class="fa fa-check"></i><b>7.5.3</b> Interpreting Durbin-Watson Statistic</a></li>
<li class="chapter" data-level="7.5.4" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#actions-to-take-if-autocorrelation-is-detected"><i class="fa fa-check"></i><b>7.5.4</b> Actions to Take if Autocorrelation is Detected</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="diagnosing-our-regression-model.html"><a href="diagnosing-our-regression-model.html#wrap-up"><i class="fa fa-check"></i><b>7.6</b> Wrap-Up</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html"><i class="fa fa-check"></i><b>8</b> Diving into Spatial Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#why-not-just-use-ordinary-regression"><i class="fa fa-check"></i><b>8.1</b> Why Not Just Use Ordinary Regression?</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#introducing-spatial-regression"><i class="fa fa-check"></i><b>8.1.1</b> Introducing Spatial Regression</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#key-concepts-in-spatial-regression"><i class="fa fa-check"></i><b>8.2</b> Key Concepts in Spatial Regression</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#why-does-this-matter"><i class="fa fa-check"></i><b>8.2.1</b> Why Does This Matter?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><i class="fa fa-check"></i><b>9</b> Robust Estimation: Dealing with Outliers and Heavy Tails</a>
<ul>
<li class="chapter" data-level="9.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#why-robust-estimation"><i class="fa fa-check"></i><b>9.1</b> Why Robust Estimation?</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#m-estimators-a-closer-look"><i class="fa fa-check"></i><b>9.1.1</b> M Estimators: A Closer Look</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#commonly-used-weight-functions"><i class="fa fa-check"></i><b>9.2</b> Commonly Used Weight Functions:</a></li>
<li class="chapter" data-level="9.3" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#mm-estimators-enhancing-robustness"><i class="fa fa-check"></i><b>9.3</b> MM Estimators: Enhancing Robustness</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#simulation-and-analysis-in-r"><i class="fa fa-check"></i><b>9.3.1</b> Simulation and Analysis in R</a></li>
<li class="chapter" data-level="9.3.2" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#observations-from-the-simulation"><i class="fa fa-check"></i><b>9.3.2</b> Observations from the Simulation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#how-robust-is-robust"><i class="fa fa-check"></i><b>9.4</b> How Robust is Robust?</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#simulation-setup"><i class="fa fa-check"></i><b>9.4.1</b> Simulation Setup</a></li>
<li class="chapter" data-level="9.4.2" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#observations-from-the-plot"><i class="fa fa-check"></i><b>9.4.2</b> Observations from the Plot</a></li>
<li class="chapter" data-level="9.4.3" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#conclusion"><i class="fa fa-check"></i><b>9.4.3</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html"><i class="fa fa-check"></i><b>10</b> Robust Standard Errors: Tackling Heteroscedasticity</a>
<ul>
<li class="chapter" data-level="10.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#visualizing-heteroscedasticity"><i class="fa fa-check"></i><b>10.1</b> Visualizing Heteroscedasticity</a></li>
<li class="chapter" data-level="10.2" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#addressing-heteroscedasticity-with-robust-standard-errors"><i class="fa fa-check"></i><b>10.2</b> Addressing Heteroscedasticity with Robust Standard Errors</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#observations-from-the-analysis"><i class="fa fa-check"></i><b>10.2.1</b> Observations from the Analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#math-behind-robust-standard-errors"><i class="fa fa-check"></i><b>10.3</b> Math Behind Robust Standard Errors</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#basic-formulation"><i class="fa fa-check"></i><b>10.3.1</b> Basic Formulation</a></li>
<li class="chapter" data-level="10.3.2" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#robust-standard-errors-1"><i class="fa fa-check"></i><b>10.3.2</b> Robust Standard Errors</a></li>
<li class="chapter" data-level="10.3.3" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#heteroscedasticity-consistent-estimators-hc"><i class="fa fa-check"></i><b>10.3.3</b> Heteroscedasticity-Consistent Estimators (HC)</a></li>
<li class="chapter" data-level="10.3.4" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#choosing-the-right-estimator"><i class="fa fa-check"></i><b>10.3.4</b> Choosing the Right Estimator</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#implementing-in-r-1"><i class="fa fa-check"></i><b>10.4</b> Implementing in R</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#ending-thoughts"><i class="fa fa-check"></i><b>10.4.1</b> Ending Thoughts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html"><i class="fa fa-check"></i><b>11</b> Time Series: Forecasting Omicron</a>
<ul>
<li class="chapter" data-level="11.0.1" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#the-power-of-time-series-estimation"><i class="fa fa-check"></i><b>11.0.1</b> The Power of Time Series Estimation</a></li>
<li class="chapter" data-level="11.0.2" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#showcasing-predictive-prowess"><i class="fa fa-check"></i><b>11.0.2</b> Showcasing Predictive Prowess</a></li>
<li class="chapter" data-level="11.1" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#data-preparation"><i class="fa fa-check"></i><b>11.1</b> Data Preparation</a></li>
<li class="chapter" data-level="11.2" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#autoregressive-integrated-moving-average-model-arima"><i class="fa fa-check"></i><b>11.2</b> Autoregressive Integrated Moving Average Model (ARIMA)</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#what-is-arima"><i class="fa fa-check"></i><b>11.2.1</b> What is ARIMA?</a></li>
<li class="chapter" data-level="11.2.2" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#components-of-arima"><i class="fa fa-check"></i><b>11.2.2</b> Components of ARIMA:</a></li>
<li class="chapter" data-level="11.2.3" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#selection-of-model-parameters"><i class="fa fa-check"></i><b>11.2.3</b> Selection of Model Parameters:</a></li>
<li class="chapter" data-level="11.2.4" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#example-usage-in-r"><i class="fa fa-check"></i><b>11.2.4</b> Example Usage in R:</a></li>
<li class="chapter" data-level="11.2.5" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#forecasting"><i class="fa fa-check"></i><b>11.2.5</b> Forecasting:</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#enhancing-predictions-with-a-neural-network"><i class="fa fa-check"></i><b>11.3</b> Enhancing Predictions with a Neural Network</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#why-neural-networks"><i class="fa fa-check"></i><b>11.3.1</b> Why Neural Networks?</a></li>
<li class="chapter" data-level="11.3.2" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#using-nnetar-for-time-series-forecasting"><i class="fa fa-check"></i><b>11.3.2</b> Using <code>nnetar</code> for Time Series Forecasting</a></li>
<li class="chapter" data-level="11.3.3" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#fitting-the-neural-network"><i class="fa fa-check"></i><b>11.3.3</b> Fitting the Neural Network</a></li>
<li class="chapter" data-level="11.3.4" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#details-of-nnetar-function"><i class="fa fa-check"></i><b>11.3.4</b> Details of <code>nnetar</code> Function:</a></li>
<li class="chapter" data-level="11.3.5" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#visualizing-neural-network-forecasts"><i class="fa fa-check"></i><b>11.3.5</b> Visualizing Neural Network Forecasts</a></li>
<li class="chapter" data-level="11.3.6" data-path="time-series-forecasting-omicron.html"><a href="time-series-forecasting-omicron.html#understanding-our-forecasting-models-performance"><i class="fa fa-check"></i><b>11.3.6</b> Understanding Our Forecasting Model’s Performance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Logistic Regression: Going Beyond Linear Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#why-use-logistic-regression"><i class="fa fa-check"></i><b>12.1</b> Why Use Logistic Regression?</a></li>
<li class="chapter" data-level="12.2" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#the-logistic-function"><i class="fa fa-check"></i><b>12.2</b> The Logistic Function</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#visualizing-the-sigmoid-function"><i class="fa fa-check"></i><b>12.2.1</b> Visualizing the Sigmoid Function</a></li>
<li class="chapter" data-level="12.2.2" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#what-does-this-plot-show"><i class="fa fa-check"></i><b>12.2.2</b> What Does This Plot Show?</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#demonstration-in-r"><i class="fa fa-check"></i><b>12.3</b> Demonstration in R</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#setting-up-the-problem-1"><i class="fa fa-check"></i><b>12.3.1</b> Setting Up the Problem</a></li>
<li class="chapter" data-level="12.3.2" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#fitting-a-logistic-regression-model"><i class="fa fa-check"></i><b>12.3.2</b> Fitting a Logistic Regression Model</a></li>
<li class="chapter" data-level="12.3.3" data-path="logistic-regression-going-beyond-linear-regression.html"><a href="logistic-regression-going-beyond-linear-regression.html#visualizing-the-results"><i class="fa fa-check"></i><b>12.3.3</b> Visualizing the Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html"><i class="fa fa-check"></i><b>13</b> Introduction to K-Means Clustering</a>
<ul>
<li class="chapter" data-level="13.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#why-k-means-clustering"><i class="fa fa-check"></i><b>13.1</b> Why K-Means Clustering?</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#how-does-k-means-work"><i class="fa fa-check"></i><b>13.1.1</b> How Does K-Means Work?</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#practical-example-k-means-on-the-iris-dataset"><i class="fa fa-check"></i><b>13.2</b> Practical Example: K-Means on the Iris Dataset</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#visualizing-k-means-clustering"><i class="fa fa-check"></i><b>13.2.1</b> Visualizing K-Means Clustering</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#the-math-of-k-means-clustering-getting-the-grouping-right"><i class="fa fa-check"></i><b>13.3</b> The Math of K-Means Clustering: Getting the Grouping Right</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#the-math-behind-perfect-grouping"><i class="fa fa-check"></i><b>13.3.1</b> The Math Behind Perfect Grouping</a></li>
<li class="chapter" data-level="13.3.2" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#how-k-means-tidies-up"><i class="fa fa-check"></i><b>13.3.2</b> How K-Means Tidies Up</a></li>
<li class="chapter" data-level="13.3.3" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#why-do-we-care"><i class="fa fa-check"></i><b>13.3.3</b> Why Do We Care?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html"><i class="fa fa-check"></i><b>14</b> Introduction to Machine Learning: Random Forests</a>
<ul>
<li class="chapter" data-level="14.1" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#why-random-forests"><i class="fa fa-check"></i><b>14.1</b> Why Random Forests?</a></li>
<li class="chapter" data-level="14.2" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#understanding-random-forests-by-starting-with-a-single-tree"><i class="fa fa-check"></i><b>14.2</b> Understanding Random Forests by Starting with a Single Tree</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#how-are-splits-determined"><i class="fa fa-check"></i><b>14.2.1</b> How are Splits Determined?</a></li>
<li class="chapter" data-level="14.2.2" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#example-decision-tree-with-the-iris-dataset"><i class="fa fa-check"></i><b>14.2.2</b> Example: Decision Tree with the Iris Dataset</a></li>
<li class="chapter" data-level="14.2.3" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#visualizing-the-decision-tree"><i class="fa fa-check"></i><b>14.2.3</b> Visualizing the Decision Tree</a></li>
<li class="chapter" data-level="14.2.4" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#decision-tree-insights"><i class="fa fa-check"></i><b>14.2.4</b> Decision Tree Insights</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#step-by-step-example-with-random-forests"><i class="fa fa-check"></i><b>14.3</b> Step-by-Step Example with Random Forests</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#setting-up-the-problem-2"><i class="fa fa-check"></i><b>14.3.1</b> Setting Up the Problem</a></li>
<li class="chapter" data-level="14.3.2" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#visualizing-the-ensemble-effect"><i class="fa fa-check"></i><b>14.3.2</b> Visualizing the Ensemble Effect</a></li>
<li class="chapter" data-level="14.3.3" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#using-the-model"><i class="fa fa-check"></i><b>14.3.3</b> Using the Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html"><i class="fa fa-check"></i><b>15</b> Wrapping Up: Fun with Numbers</a>
<ul>
<li class="chapter" data-level="15.1" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html#embrace-the-power-use-it-wisely"><i class="fa fa-check"></i><b>15.1</b> Embrace the Power, Use it Wisely</a></li>
<li class="chapter" data-level="15.2" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html#the-cautionary-note"><i class="fa fa-check"></i><b>15.2</b> The Cautionary Note</a></li>
<li class="chapter" data-level="15.3" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html#stay-curious"><i class="fa fa-check"></i><b>15.3</b> Stay Curious!</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Basic Introduction to Stats Concepts</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="diagnosing-our-regression-model" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Diagnosing Our Regression Model<a href="diagnosing-our-regression-model.html#diagnosing-our-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Alright, now that we’ve fitted our regression models, it’s crucial not to just take them at face value. Let’s dig into some diagnostics to ensure our models are robust and reliable. We’ll cover a few key diagnostics that help us validate the assumptions underlying linear regression.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="diagnosing-our-regression-model.html#cb27-1" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb27-2"><a href="diagnosing-our-regression-model.html#cb27-2" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb27-3"><a href="diagnosing-our-regression-model.html#cb27-3" tabindex="-1"></a></span>
<span id="cb27-4"><a href="diagnosing-our-regression-model.html#cb27-4" tabindex="-1"></a><span class="co"># Fitting Regression model</span></span>
<span id="cb27-5"><a href="diagnosing-our-regression-model.html#cb27-5" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> disp <span class="sc">+</span> hp <span class="sc">+</span> cyl, <span class="at">data =</span> mtcars)</span>
<span id="cb27-6"><a href="diagnosing-our-regression-model.html#cb27-6" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + disp + hp + cyl, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0562 -1.4636 -0.4281  1.2854  5.8269 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.82854    2.75747  14.807 1.76e-14 ***
## wt          -3.85390    1.01547  -3.795 0.000759 ***
## disp         0.01160    0.01173   0.989 0.331386    
## hp          -0.02054    0.01215  -1.691 0.102379    
## cyl         -1.29332    0.65588  -1.972 0.058947 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.513 on 27 degrees of freedom
## Multiple R-squared:  0.8486, Adjusted R-squared:  0.8262 
## F-statistic: 37.84 on 4 and 27 DF,  p-value: 1.061e-10</code></pre>
<div id="residuals-analysis" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Residuals Analysis<a href="diagnosing-our-regression-model.html#residuals-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before we declare victory with our model, it’s crucial to take a deep dive into the residuals, those differences between what our model predicts and what we actually observe. Residuals tell us a lot about the adequacy of the model fit. They can reveal patterns that suggest improvements are necessary, such as adjusting for non-linearity, dealing with outliers, or correcting heteroscedasticity.</p>
<div id="why-focus-on-residuals" class="section level3 hasAnchor" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Why Focus on Residuals?<a href="diagnosing-our-regression-model.html#why-focus-on-residuals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Residuals are the unexplained portion of the response variable by the predictors in the model. Ideally, these residuals should appear random and scattered without forming any identifiable patterns. Any pattern in the residuals suggests that the model is missing some aspect of the information, which is manifesting as a structure in the residuals.</p>
</div>
<div id="plotting-residuals-against-fitted-values" class="section level3 hasAnchor" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Plotting Residuals Against Fitted Values<a href="diagnosing-our-regression-model.html#plotting-residuals-against-fitted-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To visually inspect these issues, we plot residuals against fitted values. This plot helps identify several potential problems in the regression model:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="diagnosing-our-regression-model.html#cb29-1" tabindex="-1"></a><span class="fu">plot</span>(model, <span class="at">which =</span> <span class="dv">1</span>)  <span class="co"># Plots residuals against fitted values</span></span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="what-to-look-for-in-the-plot" class="section level3 hasAnchor" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> What to Look For in the Plot<a href="diagnosing-our-regression-model.html#what-to-look-for-in-the-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Randomness:</strong> Residuals should be randomly dispersed around the horizontal axis (zero line). If the residuals display a random scatter, it suggests that the model is appropriately capturing the data’s variability without systematic errors.</p></li>
<li><p><strong>Patterns or Curves:</strong> If you notice any curvature or pattern, this might indicate non-linear relationships that the linear model is not capturing.</p></li>
<li><p><strong>Funnel Shape:</strong> A spread that increases or decreases with the fitted values indicates heteroscedasticity. This condition suggests that the variance of the residuals is not constant, which can affect the reliability of the regression coefficients.</p></li>
<li><p><strong>Outliers:</strong> Points that are far from the zero line might be outliers. These are cases where the model has significantly mispredicted, and they warrant further investigation.</p></li>
</ul>
</div>
<div id="next-steps" class="section level3 hasAnchor" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> Next Steps<a href="diagnosing-our-regression-model.html#next-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Based on what the residual plot reveals, you might consider several actions to improve your model:</p>
<ul>
<li><p><strong>Transformations:</strong> Applying transformations to the dependent variable or predictors might resolve issues of non-linearity and heteroscedicity.</p></li>
<li><p><strong>Adding Predictors:</strong> Sometimes, the presence of patterns in the residuals is due to important variables missing from the model.</p></li>
<li><p><strong>Addressing Outliers:</strong> Investigating and possibly removing outliers, or using robust regression techniques that lessen the influence of outliers.</p></li>
</ul>
<p>Effective diagnostic plotting of residuals allows us to identify and correct issues with our model. By ensuring our residuals don’t show any patterns, we enhance the robustness and predictive power of our analysis, ensuring that our model performs well not just theoretically but in practical applications as well.</p>
</div>
</div>
<div id="checking-for-normality-in-residuals" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Checking for Normality in Residuals<a href="diagnosing-our-regression-model.html#checking-for-normality-in-residuals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When it comes to regression analysis, verifying the assumption of normality in the residuals is not just a pedantic detail, it’s essential. Many of the statistical tests we rely on for interpreting our models, including t-tests for coefficients and overall model F-tests, assume that these residuals follow a normal distribution. This assumption underpins our ability to trust the p-values these tests produce. So, let’s make sure we’re building our conclusions on solid ground.</p>
<div id="why-normality" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Why Normality?<a href="diagnosing-our-regression-model.html#why-normality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In simple terms, if the residuals (the differences between observed values and those predicted by our model) show a normal distribution, it suggests that our model is capturing all the systematic information in the data, leaving only the “random noise” which, ideally, is normally distributed in well-behaved data.</p>
</div>
<div id="using-a-q-q-plot-to-check-normality" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Using a Q-Q Plot to Check Normality<a href="diagnosing-our-regression-model.html#using-a-q-q-plot-to-check-normality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the most straightforward tools for checking normality is the Quantile-Quantile (Q-Q) plot. This plot helps us visually compare the distribution of the residuals to a perfect normal distribution. Here’s how you can generate this plot:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="diagnosing-our-regression-model.html#cb30-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(model))</span>
<span id="cb30-2"><a href="diagnosing-our-regression-model.html#cb30-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(model), <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>)  <span class="co"># Adds a reference line to guide the eye</span></span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="interpreting-the-q-q-plot" class="section level3 hasAnchor" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Interpreting the Q-Q Plot<a href="diagnosing-our-regression-model.html#interpreting-the-q-q-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the Q-Q plot, the x-axis displays the theoretical quantiles of the normal distribution, essentially what we would expect if the residuals were perfectly normal. The y-axis shows the actual quantiles of the residuals from our model.</p>
<ul>
<li><p><strong>What to Look For:</strong> Ideally, the points should form a straight line along the reference line provided by <code>qqline()</code>. Deviations from this line indicate departures from normality:</p>
<ul>
<li><p><strong>S-shaped curve:</strong> Indicates that the residuals have heavier tails than a normal distribution.</p></li>
<li><p><strong>Bulging patterns:</strong> Suggest that the residuals are more peaked or flat than a normal distribution.</p></li>
<li><p><strong>Outliers:</strong> Points that deviate significantly from the line can be individual cases where the model did not perform well.</p></li>
</ul></li>
</ul>
</div>
<div id="what-if-residuals-arent-normal" class="section level3 hasAnchor" number="7.2.4">
<h3><span class="header-section-number">7.2.4</span> What if Residuals Aren’t Normal?<a href="diagnosing-our-regression-model.html#what-if-residuals-arent-normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If the residuals deviate significantly from normality, it might affect the validity of some of our inference statistics. Depending on the severity and the nature of the non-normality, you might consider:</p>
<ul>
<li><p><strong>Transforming variables:</strong> Sometimes, a transformation of the response variable can lead to improvements in the normality of the residuals.</p></li>
<li><p><strong>Using different error structures:</strong> For instance, generalized linear models (GLMs) can accommodate a range of distributional assumptions beyond normality.</p></li>
<li><p><strong>Robust regression techniques:</strong> These are less sensitive to deviations from normality and can provide reliable estimates even when this assumption is violated.</p></li>
</ul>
<p>By ensuring that our residuals approximate normality, we fortify the foundation of our model’s inferential statistics, leading to more reliable and interpretable outcomes. So always take the time to check the Q-Q plot, it’s a simple yet powerful diagnostic tool in your statistical toolkit.</p>
</div>
</div>
<div id="influence-measures" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Influence Measures<a href="diagnosing-our-regression-model.html#influence-measures" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In any dataset, certain observations can disproportionately affect the fit of a regression model. You might visualize these as data points that “grab onto” the regression line and exert a strong pull, thereby potentially skewing our analysis.</p>
<div id="cooks-distance" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Cook’s Distance<a href="diagnosing-our-regression-model.html#cooks-distance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One effective method for identifying these influential data points is by using Cook’s distance. This measure helps us quantify the effect of deleting a given observation. Observations with high Cook’s distance are particularly influential and could be distorting our predictive model significantly.</p>
<p>Here’s how you can generate a Cook’s distance plot:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="diagnosing-our-regression-model.html#cb31-1" tabindex="-1"></a><span class="co"># Standard Cook&#39;s distance plot</span></span>
<span id="cb31-2"><a href="diagnosing-our-regression-model.html#cb31-2" tabindex="-1"></a><span class="fu">plot</span>(model, <span class="at">which =</span> <span class="dv">4</span>)  <span class="co"># Cook&#39;s distance plot</span></span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="using-influenceplot-for-detailed-diagnostic" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Using <code>influencePlot</code> for Detailed Diagnostic<a href="diagnosing-our-regression-model.html#using-influenceplot-for-detailed-diagnostic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For a more detailed diagnostic analysis, the <code>influencePlot</code> function from the <code>car</code> package provides a comprehensive “bubble” plot. This plot visualizes the Studentized residuals against the leverage (hat values), with bubble sizes representing the Cook’s distances. This plot is particularly useful for simultaneously assessing leverage, influence, and residuals:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="diagnosing-our-regression-model.html#cb32-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb32-2"><a href="diagnosing-our-regression-model.html#cb32-2" tabindex="-1"></a><span class="co"># Create influence plot</span></span>
<span id="cb32-3"><a href="diagnosing-our-regression-model.html#cb32-3" tabindex="-1"></a><span class="fu">influencePlot</span>(model, <span class="at">scale=</span><span class="dv">10</span>,</span>
<span id="cb32-4"><a href="diagnosing-our-regression-model.html#cb32-4" tabindex="-1"></a>              <span class="at">xlab=</span><span class="st">&quot;Hat-Values&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Studentized Residuals&quot;</span>, <span class="at">id=</span><span class="cn">TRUE</span>,</span>
<span id="cb32-5"><a href="diagnosing-our-regression-model.html#cb32-5" tabindex="-1"></a>              <span class="at">fill=</span><span class="cn">TRUE</span>, <span class="at">fill.col=</span><span class="fu">carPalette</span>()[<span class="dv">2</span>], <span class="at">fill.alpha=</span><span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre><code>##                       StudRes        Hat      CookD
## Cadillac Fleetwood -0.5092918 0.26359434 0.01909245
## Chrysler Imperial   2.1551270 0.23781201 0.25536280
## Fiat 128            2.5945269 0.08415625 0.10204889
## Toyota Corolla      2.7194282 0.10044233 0.13352159
## Maserati Bora       0.9450482 0.50998500 0.18664167</code></pre>
</div>
<div id="interpreting-the-influence-plot" class="section level3 hasAnchor" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Interpreting the Influence Plot<a href="diagnosing-our-regression-model.html#interpreting-the-influence-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Horizontal Lines</strong> at -2, 0, and 2 on the Studentized residuals scale highlight significant residual values.</p></li>
<li><p><strong>Vertical Lines</strong> at twice and three times the average hat value mark regions of high leverage.</p></li>
<li><p><strong>Bubble Size:</strong> Larger bubbles indicate higher Cook’s distances, signifying greater influence on the regression model.</p></li>
</ul>
</div>
<div id="actions-to-take" class="section level3 hasAnchor" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> Actions to Take<a href="diagnosing-our-regression-model.html#actions-to-take" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Upon identifying observations with high Cook’s distances:</p>
<ul>
<li><p><strong>Investigate the Observations:</strong> Determine if these points are due to data errors, extreme values, or are legitimate but unusual observations.</p></li>
<li><p><strong>Consider the Impact of Removal:</strong> Analyze how removing these points affects your model to decide if adjustments or a different modeling approach might be necessary.</p></li>
</ul>
<p>By utilizing Cook’s distance and influence plots, you can ensure that your model’s predictions remain robust and are not overly influenced by a few data points. Regularly examining these diagnostics helps maintain the integrity of your statistical analysis and guides you toward more reliable interpretations.</p>
</div>
</div>
<div id="multicollinearity-check" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Multicollinearity Check<a href="diagnosing-our-regression-model.html#multicollinearity-check" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When we build a model, we typically want our predictors to tell their own unique stories about the data. But what happens when they start telling the same story? This is known as multicollinearity, where predictors in a regression model are highly correlated. This excessive correlation can skew your results, making it difficult to determine the individual effect of each predictor.</p>
<div id="why-worry-about-multicollinearity" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Why Worry About Multicollinearity?<a href="diagnosing-our-regression-model.html#why-worry-about-multicollinearity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Multicollinearity doesn’t affect the model’s ability to predict the response variable; however, it does affect the precision of the estimated coefficients, which can lead to unreliable and unstable estimates of the effects. This instability means that small changes in the data could lead to large changes in the model coefficients.</p>
</div>
<div id="checking-for-multicollinearity-with-vif" class="section level3 hasAnchor" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Checking for Multicollinearity with VIF<a href="diagnosing-our-regression-model.html#checking-for-multicollinearity-with-vif" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To diagnose multicollinearity, we use the Variance Inflation Factor (VIF). It quantifies how much the variance of an estimated regression coefficient increases if your predictors are correlated. If no factors are correlated, the VIFs will all be 1.</p>
<p>Here’s how we check for multicollinearity in R:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="diagnosing-our-regression-model.html#cb34-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb34-2"><a href="diagnosing-our-regression-model.html#cb34-2" tabindex="-1"></a><span class="fu">vif</span>(model)  <span class="co"># Calculates VIF for each predictor</span></span></code></pre></div>
<pre><code>##        wt      disp        hp       cyl 
##  4.848016 10.373286  3.405983  6.737707</code></pre>
</div>
<div id="interpreting-vif-values" class="section level3 hasAnchor" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Interpreting VIF Values<a href="diagnosing-our-regression-model.html#interpreting-vif-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>VIF Value 1:</strong> Indicates no correlation among the <span class="math inline">\(k^{th}\)</span> predictor and the remaining predictor variables.</p></li>
<li><p><strong>VIF Values between 1 and 5:</strong> Suggest moderate correlation, but they are often not concerning.</p></li>
<li><p><strong>VIF Values above 5:</strong> Signal that the regression coefficients are poorly estimated due to substantial multicollinearity; some sources suggest a cutoff of 10, which indicates serious multicollinearity that needs to be addressed.</p></li>
</ul>
</div>
<div id="how-to-address-high-vifs" class="section level3 hasAnchor" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> How to Address High VIFs<a href="diagnosing-our-regression-model.html#how-to-address-high-vifs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you find a high VIF in your analysis:</p>
<ul>
<li><p><strong>Remove highly correlated predictors:</strong> Simplify the model by removing redundant variables.</p></li>
<li><p><strong>Combine predictors:</strong> Sometimes, combining correlated variables into a single predictor can help.</p></li>
<li><p><strong>Center the variables:</strong> Subtracting the mean can sometimes help reduce multicollinearity without losing any important information.</p></li>
</ul>
<p>Understanding and managing multicollinearity is crucial for ensuring the validity of your regression analysis. By regularly checking VIF and taking corrective action when necessary, we can maintain the integrity and interpretability of our models, ensuring that each predictor contributes its unique piece of the story.</p>
</div>
</div>
<div id="autocorrelation-test" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Autocorrelation Test<a href="diagnosing-our-regression-model.html#autocorrelation-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the realm of time series analysis, one crucial assumption we often overlook is that of independence among residuals. When residuals are not independent, commonly seen as autocorrelation, it can lead to misleading inferences about the relationships in your data. This is because standard errors can become understated, leading to confidence intervals that are too narrow and p-values that falsely suggest significance.</p>
<div id="what-is-autocorrelation" class="section level3 hasAnchor" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> What is Autocorrelation?<a href="diagnosing-our-regression-model.html#what-is-autocorrelation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Autocorrelation occurs when the residuals from one time point are correlated with the residuals from another, which often happens in data collected over time. This can be due to trends, cyclic patterns, or other serial dependencies not captured by the model.</p>
</div>
<div id="testing-autocorrelation-with-durbin-watson" class="section level3 hasAnchor" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Testing Autocorrelation with Durbin-Watson<a href="diagnosing-our-regression-model.html#testing-autocorrelation-with-durbin-watson" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To detect the presence of autocorrelation, we employ the Durbin-Watson (DW) test. This test provides a statistic that quantifies the degree of serial correlation. Here’s how you can perform the DW test in R:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="diagnosing-our-regression-model.html#cb36-1" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb36-2"><a href="diagnosing-our-regression-model.html#cb36-2" tabindex="-1"></a><span class="fu">dwtest</span>(model)</span></code></pre></div>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  model
## DW = 1.685, p-value = 0.09982
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
</div>
<div id="interpreting-durbin-watson-statistic" class="section level3 hasAnchor" number="7.5.3">
<h3><span class="header-section-number">7.5.3</span> Interpreting Durbin-Watson Statistic<a href="diagnosing-our-regression-model.html#interpreting-durbin-watson-statistic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>DW Statistic Close to 2.0:</strong> Indicates no autocorrelation. The residuals from one period are not influenced by those from the previous periods.</p></li>
<li><p><strong>DW Statistic Significantly Greater than 2.0:</strong> Suggests negative autocorrelation. This is less common but could indicate an overcorrection in your model.</p></li>
<li><p><strong>DW Statistic Significantly Less than 2.0:</strong> Suggests positive autocorrelation. This is more usual and means that a positive error in one period likely leads to a positive error in the next.</p></li>
</ul>
</div>
<div id="actions-to-take-if-autocorrelation-is-detected" class="section level3 hasAnchor" number="7.5.4">
<h3><span class="header-section-number">7.5.4</span> Actions to Take if Autocorrelation is Detected<a href="diagnosing-our-regression-model.html#actions-to-take-if-autocorrelation-is-detected" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you find evidence of autocorrelation:</p>
<ul>
<li><p><strong>Adding Lags:</strong> Incorporate lags of the dependent variable or residuals as additional predictors to capture the temporal dynamics.</p></li>
<li><p><strong>Differencing:</strong> Apply differencing to the data series to remove trends or cycles that might be inducing autocorrelation.</p></li>
<li><p><strong>Adjusting the Model:</strong> Consider using time series-specific models like ARIMA, which are designed to handle autocorrelation and non-stationarity within the data.</p></li>
</ul>
<p>Autocorrelation can seriously skew the results of a time series analysis, but with the right tests and adjustments, you can ensure your model accurately reflects the true dynamics of the data. Always check for autocorrelation in time series models to avoid the pitfalls of correlated errors, keeping your conclusions both robust and reliable.</p>
</div>
</div>
<div id="wrap-up" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> Wrap-Up<a href="diagnosing-our-regression-model.html#wrap-up" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Performing these diagnostics doesn’t just safeguard the reliability of our conclusions; it deepens our understanding of the data’s underlying structures and behaviors. It’s like getting a peek behind the curtains of our statistical models, ensuring that what we see on the stage is truly reflective of the script. Let’s keep our analyses robust and our interpretations sharp!</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="diving-into-spatial-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/DanBaissa/Intro_to_Stats/edit/master/0401-lm.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
